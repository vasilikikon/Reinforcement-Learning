{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7154ac1e-7ac9-4def-90d1-f73e2268621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python --version\n",
    "#! pip install gym==0.21.0\n",
    "#! pip install gym-retro==0.8.0\n",
    "# !pip install stable-baselines3[extra]\n",
    "# !pip install gymnasium[all]\n",
    "#!pip install opencv-python\n",
    "import retro\n",
    "import numpy as np # to calculate the delta between the frames\n",
    "import cv2 # for grayscaling\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76337f3b-5594-4c97-b8b0-19638888961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "1000.0\n",
      "500.0\n",
      "300.0\n",
      "400.0\n",
      "1000.0\n"
     ]
    }
   ],
   "source": [
    "#! python -m retro.import .\n",
    "# retro.data.list_games()\n",
    "# creating our game environment\n",
    "env = retro.make(game=\"StreetFighterIISpecialChampionEdition-Genesis\")\n",
    "env.observation_space\n",
    "env.action_space\n",
    "env.action_space.sample()\n",
    "\n",
    "obs = env.reset() # Reset game to starting state\n",
    "\n",
    "done = False # Set flag to flase, tells us when we dies\n",
    "for game in range(1): # play one game \n",
    "   while not done: \n",
    "       if done: \n",
    "           obs = env.reset() # when we do die, we start the game again\n",
    "       env.render()\n",
    "       obs, reward, done, info = env.step(env.action_space.sample()) # randomly take action\n",
    "       time.sleep(0.000000001)\n",
    "       if reward > 0:\n",
    "           print(reward) # only a number when win, no rewards when getting along which makes it hard to train rl agent - sparse rewards\n",
    "        #need to change this, as the spare rewards will make it hard to train the rl agent\n",
    "info\n",
    "env.close()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dffce-242d-45f5-8175-6c4ddcbb5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import MultiBinary, Box\n",
    "#Creating custom environment that will carry out all the steps\n",
    "#we pass our pass environment\n",
    "\n",
    "class StreetFighter(Env): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Specify action space and observation space \n",
    "        # resizing and making gray scale\n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8) \n",
    "        self.action_space = MultiBinary(12)\n",
    "        # Startup and instance of the game \n",
    "        # additional parameter to filter only valid actions\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
    "    \n",
    "    def reset(self):\n",
    "        # Return the first frame \n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs) \n",
    "        self.previous_frame = obs # want to also keep track of the previous frame to calculate a delta between the frames\n",
    "        \n",
    "        # Create a attribute to hold the score delta \n",
    "        self.score = 0 \n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation): \n",
    "        # Grayscaling \n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize \n",
    "        resize = cv2.resize(gray, (84,84), interpolation=cv2.INTER_CUBIC)\n",
    "        # Add the channels value\n",
    "        channels = np.reshape(resize, (84,84,1))\n",
    "        return channels \n",
    "    \n",
    "    def step(self, action): \n",
    "        # Take a step \n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs = self.preprocess(obs) \n",
    "        \n",
    "        # Frame delta - use this to train our agent\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Reshape the reward function\n",
    "        reward = info['score'] - self.score \n",
    "        self.score = info['score'] \n",
    "        \n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "\n",
    "env = StreetFighter()\n",
    "env.observation_space\n",
    "env.action_space.sample()\n",
    "\n",
    "obs = env.reset() # Reset game to starting state\n",
    "\n",
    "done = False # Set flag to flase, tells us when we die\n",
    "for game in range(1): # play one game \n",
    "   while not done: \n",
    "       env.render()\n",
    "       obs, reward, done, info = env.step(env.action_space.sample()) # randomly take action 'max score 74900'\n",
    "       time.sleep(0.000001)\n",
    "       if reward > 0:\n",
    "           print(reward) # only a number when win, no rewards when getting along which makes it hard to train rl agent - sparse rewards\n",
    "        #need to change this, as the spare rewards will make it hard to train the rl agent\n",
    "info\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f991c-ec3b-44e0-b6d1-eac459d099ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env\n",
    "from gym.spaces import Box, MultiBinary\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Define the custom environment class\n",
    "class StreetFighter(Env):\n",
    "    def __init__(self, render_mode='human'):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "        self.action_space = MultiBinary(12)\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs)\n",
    "        self.previous_frame = obs\n",
    "        self.score = 0\n",
    "        return obs\n",
    "\n",
    "    def preprocess(self, observation):\n",
    "        gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_CUBIC)\n",
    "        channels = np.reshape(resize, (84, 84, 1))\n",
    "        return channels\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs = self.preprocess(obs)\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs\n",
    "        reward = info['score'] - self.score\n",
    "        self.score = info['score']\n",
    "        return frame_delta, reward, done, info\n",
    "\n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render(mode=self.render_mode)\n",
    "     \n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n",
    "# Create the environment\n",
    "env = StreetFighter(render_mode='human') #StreetFighter()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Define the PPO model with the custom environment\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=\"./street_fighter_ppo/\")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=10)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"ppo_street_fighter\")\n",
    "\n",
    "# Load the trained model (if not already loaded)\n",
    "model = PPO.load(\"ppo_street_fighter\", env=env)\n",
    "\n",
    "# Run the game loop with the trained model\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    env.render()\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    time.sleep(0.000001)\n",
    "    if reward > 0:\n",
    "        print(reward)\n",
    "\n",
    "\n",
    "info\n",
    "env.close()\n",
    "\n",
    "#100000 steps max score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60565977-fc4c-4c76-8264-8164d9a3a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "# from gymnasium import Env\n",
    "# from gymnasium.spaces import Box, MultiBinary\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# # Define the custom environment class\n",
    "# class StreetFighter(Env):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.observation_space = Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "#         self.action_space = MultiBinary(12)\n",
    "#         self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
    "\n",
    "#     def reset(self, seed=None, options=None):\n",
    "#         if seed is not None:\n",
    "#             self.game.seed(seed)\n",
    "#         obs = self.game.reset()\n",
    "#         obs = self.preprocess(obs)\n",
    "#         self.previous_frame = obs\n",
    "#         self.score = 0\n",
    "#         return obs, {}\n",
    "\n",
    "#     def preprocess(self, observation):\n",
    "#         gray = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "#         resize = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_CUBIC)\n",
    "#         channels = np.reshape(resize, (84, 84, 1))\n",
    "#         return channels\n",
    "\n",
    "#     def step(self, action):\n",
    "#         obs, reward, done, info = self.game.step(action)\n",
    "#         obs = self.preprocess(obs)\n",
    "#         frame_delta = obs - self.previous_frame\n",
    "#         self.previous_frame = obs\n",
    "#         reward = info['score'] - self.score\n",
    "#         self.score = info['score']\n",
    "#         return frame_delta, reward, done, False, info\n",
    "\n",
    "#     def render(self, *args, **kwargs):\n",
    "#         self.game.render()\n",
    "\n",
    "#     def close(self):\n",
    "#         self.game.close()\n",
    "\n",
    "# # Create the environment\n",
    "# env = StreetFighter()\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# # Define the PPO model with the custom environment\n",
    "# model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=\"./street_fighter_ppo/\")\n",
    "\n",
    "# # Train the model\n",
    "# model.learn(total_timesteps=100)\n",
    "\n",
    "# # Save the trained model\n",
    "# model.save(\"ppo_street_fighter\")\n",
    "\n",
    "# # Load the trained model (if not already loaded)\n",
    "# model = PPO.load(\"ppo_street_fighter\", env=env)\n",
    "\n",
    "# # Run the game loop with the trained model\n",
    "# obs = env.reset()\n",
    "# done = False\n",
    "\n",
    "# while not done:\n",
    "#     env.render()\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "#     time.sleep(0.000001)\n",
    "#     if reward > 0:\n",
    "#         print(reward)\n",
    "\n",
    "# info\n",
    "#env.close()\n",
    "\n",
    "#MAX score 27200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
