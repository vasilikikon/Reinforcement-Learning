{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4507ef8-cbdf-4586-bc82-3fd23c4e26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import retro # to play street fighter using o ROM\n",
    "import time\n",
    "from gym import Env # to wrap the environment\n",
    "from gym.spaces import MultiBinary, Box\n",
    "import numpy as np # to calculate the delta between the frames\n",
    "import cv2 # for grayscaling\n",
    "from stable_baselines3 import PPO\n",
    "from gym.wrappers import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d41c201-3760-4833-be6b-0271b224a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom environment that will carry out all the steps we pass our environment\n",
    "\n",
    "screen_size = 84\n",
    "\n",
    "class StreetFighter(Env): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Specify action space and observation space \n",
    "        # resizing and making gray scale\n",
    "        self.observation_space = Box(low=0, high=255, shape=(screen_size, screen_size, 1), dtype=np.uint8) \n",
    "        self.action_space = MultiBinary(12)\n",
    "        # Startup and instance of the game \n",
    "        # additional parameter to filter only valid actions\n",
    "        self.game = retro.make(game='StreetFighterIISpecialChampionEdition-Genesis', use_restricted_actions=retro.Actions.FILTERED)\n",
    "    \n",
    "    def reset(self):\n",
    "        # Return the first frame \n",
    "        obs = self.game.reset()\n",
    "        obs = self.preprocess(obs) \n",
    "        self.previous_frame = obs # want to also keep track of the previous frame to calculate a delta between the frames\n",
    "        \n",
    "        # Create a attribute to hold the score delta \n",
    "        self.score = 0 \n",
    "\n",
    "        print(\"reset\")\n",
    "        return obs\n",
    "    \n",
    "    def preprocess(self, observation):\n",
    "        # Convert the image to HSV color space\n",
    "        hsv = cv2.cvtColor(observation, cv2.COLOR_BGR2HSV) \n",
    "        # Define color ranges for red, blue, and green in HSV\n",
    "        lower_red1 = np.array([0, 50, 50])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([170, 50, 50])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "        lower_blue = np.array([100, 50, 50])\n",
    "        upper_blue = np.array([140, 255, 255])\n",
    "        lower_green = np.array([40, 50, 50])\n",
    "        upper_green = np.array([80, 255, 255])       \n",
    "        # Create masks for red, blue, and green colors\n",
    "        mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "        mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "        mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "        mask_green = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        # Combine the masks\n",
    "        mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "        mask = cv2.bitwise_or(mask_red, mask_blue)\n",
    "        mask = cv2.bitwise_or(mask, mask_green)\n",
    "        # Apply the mask to the original image\n",
    "        filtered = cv2.bitwise_and(observation, observation, mask=mask) \n",
    "        # Convert the filtered image to grayscale\n",
    "        gray = cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize the image\n",
    "        resize = cv2.resize(gray, (screen_size, screen_size), interpolation=cv2.INTER_CUBIC)\n",
    "        if np.random.rand() > 0.5:\n",
    "            resize = cv2.flip(resize, 1)  # Flip the image horizontally\n",
    "        # Add the channels value\n",
    "        channels = np.reshape(resize, (screen_size, screen_size, 1))\n",
    "        return channels\n",
    "    \n",
    "    def step(self, action): \n",
    "        # Take a step\n",
    "        obs, reward, done, info = self.game.step(action)\n",
    "        obs = self.preprocess(obs) \n",
    "        \n",
    "        # Frame delta - use this to train our agent\n",
    "        frame_delta = obs - self.previous_frame\n",
    "        self.previous_frame = obs \n",
    "        \n",
    "        # Reshape the reward function\n",
    "        reward = info['score'] - self.score + 0.1  # Add a small reward for staying alive\n",
    "        self.score = info['score'] \n",
    "        \n",
    "        return frame_delta, reward, done, info\n",
    "    \n",
    "    def render(self, *args, **kwargs):\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.game.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87d7d48-4b98-45aa-9e72-fdccf8fd72c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\gym\\wrappers\\monitor.py:86: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x0000017103C81FD0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x0000017103C78730>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 149  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 27   |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:284: UserWarning: Path 'training\\models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n",
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\gym\\wrappers\\monitor.py:86: UserWarning: \u001b[33mWARN: Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vasil\\miniconda3\\envs\\fight\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "reset\n",
      "Mean reward: 3284.7549508530647\n"
     ]
    }
   ],
   "source": [
    "env = StreetFighter()\n",
    "env = Monitor(env, './logs/', force=True)  # Wrap the environment with Monitor and force clear previous files\n",
    "\n",
    "# This is the AI model started\n",
    "#model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=\"training/Logs\")\n",
    "model = PPO('CnnPolicy', env, verbose=1, learning_rate=0.0001, n_steps=4096, batch_size=64, n_epochs=10, gamma=0.99)\n",
    "\n",
    "\n",
    "# Define a callback for evaluation\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/', log_path='./logs/', eval_freq=5000, n_eval_episodes=5, render=False)\n",
    "\n",
    "# Train the AI model, this is where the AI model starts to learn\n",
    "timesteps = 1\n",
    "model.learn(total_timesteps=timesteps, callback=eval_callback)\n",
    "\n",
    "# save the model\n",
    "#model.save(f\"training/models/PPO_{timesteps}_SF\")\n",
    "model.save(\"training/models/PPO_StreetFighter\")\n",
    "\n",
    "# Close the training environment to avoid emulator conflict\n",
    "env.close()\n",
    "\n",
    "# Create a new evaluation environment and wrap it with Monitor\n",
    "eval_env = StreetFighter()\n",
    "eval_env = Monitor(eval_env, './logs/', force=True)\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(\"training/models/PPO_StreetFighter\")\n",
    "\n",
    "# Evaluate the model\n",
    "mean_reward, _ = evaluate_policy(model, eval_env, render=True, n_eval_episodes=20)\n",
    "print(f\"Mean reward: {mean_reward}\")\n",
    "\n",
    "# Close the evaluation environment\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3fcf9b-b90b-41ad-8af6-90823c70cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "{'enemy_matches_won': 2, 'score': 2900, 'matches_won': 0, 'continuetimer': 10, 'enemy_health': 0, 'health': 0}\n"
     ]
    }
   ],
   "source": [
    "# create new environment\n",
    "env = StreetFighter()\n",
    "env.observation_space.shape\n",
    "env.action_space.shape\n",
    "\n",
    "model = PPO.load(\"training/models/PPO_StreetFighter\")\n",
    "\n",
    "# Reset game to starting state\n",
    "obs = env.reset()\n",
    "# Set flag to false\n",
    "done = False\n",
    "for game in range(1): \n",
    "    while not done: \n",
    "        if done: \n",
    "            obs = env.reset()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        \n",
    "        #time.sleep(0.01)\n",
    "        # print(reward)\n",
    "        #if reward > 0: \n",
    "            #print(reward)\n",
    "\n",
    "print(info)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
